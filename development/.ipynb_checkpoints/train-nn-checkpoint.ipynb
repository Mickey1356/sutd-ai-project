{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ad8e43",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "\n",
    "In this notebook, we build a simple Neural Network and train it on the data generated by `data-integration.ipynb`.\n",
    "\n",
    "We then save it as `bang_model`. The saved model can then be copied into the deployment folder so the deployment script can use the generated model to make predictions accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c50cfe6",
   "metadata": {
    "id": "02711b14"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4d5cb7",
   "metadata": {
    "id": "74dc58a5"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('bb_final.csv')\n",
    "df = df.append(pd.read_csv('amc_final.csv'), ignore_index=True)\n",
    "df = df.append(pd.read_csv('nok_final.csv'), ignore_index=True)\n",
    "df = df.append(pd.read_csv('gme_final.csv'), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1132310",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "579ce008",
    "outputId": "f0f2b077-7b65-4a80-8dbf-3741e728e22e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>accumulated_n</th>\n",
       "      <th>accumulated_s</th>\n",
       "      <th>accumulated_r</th>\n",
       "      <th>accumulated_sentiment</th>\n",
       "      <th>positive_count</th>\n",
       "      <th>negative_count</th>\n",
       "      <th>neutral_count</th>\n",
       "      <th>price_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.017910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>1449.500000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>142.666667</td>\n",
       "      <td>231.333333</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>45.666667</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>123</td>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>19.384615</td>\n",
       "      <td>38.153846</td>\n",
       "      <td>0.857179</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.040016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>124</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>71.650000</td>\n",
       "      <td>65.300000</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.020981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>125</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>24.772727</td>\n",
       "      <td>49.909091</td>\n",
       "      <td>0.839091</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>126</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>73.120000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.012688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>127</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>19.147059</td>\n",
       "      <td>27.558824</td>\n",
       "      <td>0.816176</td>\n",
       "      <td>1.147059</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.021222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        Date  ...  neutral_count  price_change\n",
       "0             0  2021-01-04  ...              0     -0.017910\n",
       "1             1  2021-01-05  ...              0      0.022659\n",
       "2             2  2021-01-06  ...              0      0.000000\n",
       "3             3  2021-01-07  ...              0      0.045926\n",
       "4             4  2021-01-08  ...              0      0.047091\n",
       "..          ...         ...  ...            ...           ...\n",
       "507         123  2021-06-24  ...              5     -0.040016\n",
       "508         124  2021-06-25  ...              1     -0.020981\n",
       "509         125  2021-06-28  ...              1      0.009467\n",
       "510         126  2021-06-29  ...              3     -0.012688\n",
       "511         127  2021-06-30  ...              2      0.021222\n",
       "\n",
       "[512 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33b36d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "7e04f331",
    "outputId": "2df1dbc8-9c23-493c-e993-103a95edb16e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accumulated_n</th>\n",
       "      <th>accumulated_s</th>\n",
       "      <th>accumulated_r</th>\n",
       "      <th>accumulated_sentiment</th>\n",
       "      <th>price_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.017910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126.000000</td>\n",
       "      <td>1449.500000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.022659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142.666667</td>\n",
       "      <td>231.333333</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.045926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.666667</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>19.384615</td>\n",
       "      <td>38.153846</td>\n",
       "      <td>0.857179</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>-0.040016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>71.650000</td>\n",
       "      <td>65.300000</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>-0.020981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>24.772727</td>\n",
       "      <td>49.909091</td>\n",
       "      <td>0.839091</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>0.009467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>73.120000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>-0.012688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>19.147059</td>\n",
       "      <td>27.558824</td>\n",
       "      <td>0.816176</td>\n",
       "      <td>1.147059</td>\n",
       "      <td>0.021222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     accumulated_n  accumulated_s  ...  accumulated_sentiment  price_change\n",
       "0         9.000000       1.000000  ...               2.000000     -0.017910\n",
       "1       126.000000    1449.500000  ...               2.000000      0.022659\n",
       "2        30.000000       1.500000  ...               1.500000      0.000000\n",
       "3       142.666667     231.333333  ...               2.000000      0.045926\n",
       "4        45.666667      36.666667  ...               1.000000      0.047091\n",
       "..             ...            ...  ...                    ...           ...\n",
       "507      19.384615      38.153846  ...               0.358974     -0.040016\n",
       "508      71.650000      65.300000  ...               1.550000     -0.020981\n",
       "509      24.772727      49.909091  ...               1.090909      0.009467\n",
       "510      22.000000      73.120000  ...               1.280000     -0.012688\n",
       "511      19.147059      27.558824  ...               1.147059      0.021222\n",
       "\n",
       "[512 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['accumulated_n', 'accumulated_s', 'accumulated_r', 'accumulated_sentiment', 'price_change']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c1289",
   "metadata": {
    "id": "b4314a5f"
   },
   "outputs": [],
   "source": [
    "#shuffle here\n",
    "df = df.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ee795",
   "metadata": {
    "id": "baecbe1b"
   },
   "outputs": [],
   "source": [
    "def train_test_split(df):\n",
    "\n",
    "    percentage_train = 0.9\n",
    "    percentage_test = 1 - percentage_train\n",
    "\n",
    "    train_df = df.iloc[int(len(df) * (1 - percentage_train)):]\n",
    "    test_df = df.iloc[:int(len(df) * percentage_test)]\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d1e5a",
   "metadata": {
    "id": "3c4399cc"
   },
   "outputs": [],
   "source": [
    "train_target = torch.tensor(train_df['price_change'].values.astype(np.float32))\n",
    "train = torch.tensor(train_df.drop('price_change', axis = 1).values.astype(np.float32)) \n",
    "train_tensor = data_utils.TensorDataset(train, train_target) \n",
    "train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = 8, shuffle = True)\n",
    "\n",
    "\n",
    "test_target = torch.tensor(test_df['price_change'].values.astype(np.float32))\n",
    "test = torch.tensor(test_df.drop('price_change', axis = 1).values.astype(np.float32)) \n",
    "test_tensor = data_utils.TensorDataset(test, test_target) \n",
    "test_loader = data_utils.DataLoader(dataset = test_tensor, batch_size = 8, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db01d3a8",
   "metadata": {
    "id": "4c3e2c82"
   },
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        \n",
    "        hidden_dim1 = 4\n",
    "        hidden_dim2 = 2\n",
    "        \n",
    "        # Linear function\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1) \n",
    "\n",
    "        # Linear function\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2) \n",
    "        \n",
    "        # Linear function\n",
    "        self.fc3 = nn.Linear(hidden_dim2, output_dim) \n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b993e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87c04347",
    "outputId": "9d0e744f-73c5-4e5f-bcf6-e9dbcb73cfa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0858, -0.1880,  0.2764,  0.2023],\n",
      "        [ 0.1701, -0.3416, -0.1855, -0.2859],\n",
      "        [ 0.0607,  0.0095,  0.3775,  0.0980],\n",
      "        [-0.1837,  0.2091,  0.3222,  0.0162]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2056, -0.2588,  0.1123, -0.0746], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1043, -0.2275, -0.2595,  0.1389],\n",
      "        [-0.2573, -0.3383,  0.3099, -0.2891]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2928,  0.2395], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.5258, -0.3553]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2899], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = FeedforwardNeuralNetModel(4,1)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.01\n",
    "num_epochs = 20\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "for parameter in model.parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e41de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51460e98",
    "outputId": "9e47aed3-de54-47c6-f8b8-14e8aa86cf57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([5])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100. Loss: 11.627667427062988. Same-sign accuracy: 0.6470588235294118\n",
      "Iteration: 200. Loss: 0.10956484824419022. Same-sign accuracy: 0.6274509803921569\n",
      "Iteration: 300. Loss: 0.04278528690338135. Same-sign accuracy: 0.5882352941176471\n",
      "Iteration: 400. Loss: 0.005025673191994429. Same-sign accuracy: 0.5882352941176471\n",
      "Iteration: 500. Loss: 0.00043049504165537655. Same-sign accuracy: 0.6274509803921569\n",
      "Iteration: 600. Loss: 0.0009650642750784755. Same-sign accuracy: 0.6078431372549019\n",
      "Iteration: 700. Loss: 0.0016456940211355686. Same-sign accuracy: 0.6274509803921569\n",
      "Iteration: 800. Loss: 0.0013848482631146908. Same-sign accuracy: 0.5686274509803921\n",
      "Iteration: 900. Loss: 0.001629339181818068. Same-sign accuracy: 0.5294117647058824\n",
      "Iteration: 1000. Loss: 0.00016336588305421174. Same-sign accuracy: 0.5686274509803921\n",
      "Iteration: 1100. Loss: 0.0013650002656504512. Same-sign accuracy: 0.5686274509803921\n"
     ]
    }
   ],
   "source": [
    "iter_count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, price_change) in enumerate(train_loader):\n",
    "\n",
    "        #Clear gradients \n",
    "        optimizer.zero_grad()\n",
    "        #print(data)\n",
    "        #Forward pass to get output\n",
    "        outputs = model(data)\n",
    "        \n",
    "        #print(outputs)\n",
    "        #print(price_change)\n",
    "        #print(\"\\n\")\n",
    "\n",
    "        #Calculate Loss with cross entropy loss function\n",
    "        loss = criterion(outputs, price_change)\n",
    "\n",
    "        #Getting gradients and updating parameters with backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iter_count += 1\n",
    "        \n",
    "        if iter_count % 100 == 0:    \n",
    "            total = 0\n",
    "            same_sign = 0\n",
    "            for data, price_change in test_loader:\n",
    "\n",
    "                #Forward pass to get output\n",
    "                outputs = model(data)\n",
    "                #check for equivalent signs as an indicator of model's effectiveness\n",
    "                for index in range(len(outputs)):\n",
    "                  total += 1\n",
    "                  if (outputs[index] * price_change[index] >= 0):\n",
    "                    same_sign += 1\n",
    "                loss = criterion(outputs, price_change)\n",
    "                \n",
    "            print('Iteration: {}. Loss: {}. Same-sign accuracy: {}'.format(iter_count, loss.item(), same_sign/total))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23407f1",
   "metadata": {
    "id": "7d0a45ec"
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "torch.save(model.state_dict(), 'bang_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5507f01",
   "metadata": {},
   "source": [
    "## Deployment code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd0c5d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "899c47c8",
    "outputId": "e1b41b13-63c1-4e12-f3b7-6e6f3dd77a49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bang_bang = FeedforwardNeuralNetModel(4,1)\n",
    "\n",
    "bang_bang.load_state_dict(torch.load('bang_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a886e317",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0c1a14b",
    "outputId": "e5b9eca3-3caf-4b3b-9655-2daa14009eac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3483]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "new_input = [10.0,10.10,90.90,-1.0]\n",
    "\n",
    "output = bang_bang(torch.tensor(torch.tensor([new_input])))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dae54b",
   "metadata": {
    "id": "Rv2U23McXL5N"
   },
   "source": [
    "## Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f37892b",
   "metadata": {
    "id": "7X3MAgH7XMtL"
   },
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        \n",
    "        hidden_dim1 = 4\n",
    "        hidden_dim2 = 2\n",
    "        \n",
    "        # Linear function\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1) \n",
    "\n",
    "        # Linear function\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2) \n",
    "        \n",
    "        # Linear function\n",
    "        self.fc3 = nn.Linear(hidden_dim2, output_dim) \n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77be8d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_o6AaepsXTyN",
    "outputId": "c4b57563-ef52-43b4-b73a-540757d67b9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bang_bang = FeedforwardNeuralNetModel(4,1)\n",
    "\n",
    "bang_bang.load_state_dict(torch.load('bang_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad3e0b0",
   "metadata": {
    "id": "QPAO2u69Xy7j"
   },
   "outputs": [],
   "source": [
    "new_input = [10.0,10.100,90.90,2.0]\n",
    "actual_change = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d9f8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wj7Vfq6WXeQc",
    "outputId": "765540c4-ced4-42b5-d454-a377819beb1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "learning_rate= 0.01\n",
    "optimizer = torch.optim.Adam(bang_bang.parameters(), lr=learning_rate)  \n",
    "\n",
    "#Clear gradients \n",
    "optimizer.zero_grad()\n",
    "#print(data)\n",
    "#Forward pass to get output\n",
    "outputs = bang_bang(torch.tensor(torch.tensor([new_input])))\n",
    "\n",
    "#print(outputs)\n",
    "#print(price_change)\n",
    "#print(\"\\n\")\n",
    "\n",
    "#Calculate Loss with cross entropy loss function\n",
    "loss = criterion(outputs, torch.tensor([actual_change]))\n",
    "\n",
    "#Getting gradients and updating parameters with backpropagation\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bec6e7",
   "metadata": {
    "id": "n8IVCVDjX1ml"
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "torch.save(model.state_dict(), 'bang_model')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BANG_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
