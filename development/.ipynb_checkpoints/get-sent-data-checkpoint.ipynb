{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Sentiment Data\n",
    "\n",
    "We tried out vaderSentiment (https://github.com/cjhutto/vaderSentiment) as one of the approaches used to generate sentiment data for use as features for our model.\n",
    "\n",
    "In this notebook, we used vaderSentiment to generate sentiment labels for every single post, and store them in a column under `sentiment`.\n",
    "\n",
    "For each sentiment label generated by vaderSentiment (-2, -1, 0, 1, 2), we sampled 100 posts in order to manually verify that the results are acceptable.\n",
    "\n",
    "Sentiment, by its very nature, is extremely subjective. From a cursory glance, sadly, we saw that the sampled posts (which would be generated by this notebook in `sentiment_df.csv`) usually did not match the sentiments assigned to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30987,
     "status": "ok",
     "timestamp": 1628079721858,
     "user": {
      "displayName": "Heng jing han",
      "photoUrl": "",
      "userId": "01148339297681775778"
     },
     "user_tz": -480
    },
    "id": "8moektB0quvN",
    "outputId": "1149ad0c-f5a9-4fbb-e172-46fd469778a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8357,
     "status": "ok",
     "timestamp": 1628079730209,
     "user": {
      "displayName": "Heng jing han",
      "photoUrl": "",
      "userId": "01148339297681775778"
     },
     "user_tz": -480
    },
    "id": "0UruNGr0P__b"
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv(\"01-updated.csv\")\n",
    "df = df.append(pd.read_csv(\"02-updated.csv\"), ignore_index=True)\n",
    "df = df.append(pd.read_csv(\"03-updated.csv\"), ignore_index=True)\n",
    "df = df.append(pd.read_csv(\"04-updated.csv\"), ignore_index=True)\n",
    "df = df.append(pd.read_csv(\"05-updated.csv\"), ignore_index=True)\n",
    "df = df.append(pd.read_csv(\"06-updated.csv\"), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1628079732453,
     "user": {
      "displayName": "Heng jing han",
      "photoUrl": "",
      "userId": "01148339297681775778"
     },
     "user_tz": -480
    },
    "id": "o7sdktcUQADD"
   },
   "outputs": [],
   "source": [
    "#score indication:  -2:strongly negative    -1:negative   0:neutral     1:positive    2:strongly positive\n",
    "def sentiment_analyzer_scores(row):\n",
    "    score = analyser.polarity_scores(row['p'])\n",
    "    score = float(str(score['compound']))\n",
    "    if score != 0:\n",
    "        new_score = score * 2\n",
    "        if new_score > 0:\n",
    "          new_score += 0.5\n",
    "        else:\n",
    "          new_score -= 0.5\n",
    "    else:\n",
    "        new_score = 0\n",
    "    return int(new_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 265787,
     "status": "ok",
     "timestamp": 1628080000362,
     "user": {
      "displayName": "Heng jing han",
      "photoUrl": "",
      "userId": "01148339297681775778"
     },
     "user_tz": -480
    },
    "id": "9O_-gB-3Sej8"
   },
   "outputs": [],
   "source": [
    "df['sentiment'] = df.apply(sentiment_analyzer_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6259,
     "status": "ok",
     "timestamp": 1628080006596,
     "user": {
      "displayName": "Heng jing han",
      "photoUrl": "",
      "userId": "01148339297681775778"
     },
     "user_tz": -480
    },
    "id": "6cTRLgebScXs"
   },
   "outputs": [],
   "source": [
    "max_sample_len = 100\n",
    "\n",
    "neg2 = deque(maxlen=max_sample_len)\n",
    "neg1 = deque(maxlen=max_sample_len)\n",
    "zero = deque(maxlen=max_sample_len)\n",
    "pos1 = deque(maxlen=max_sample_len)\n",
    "pos2 = deque(maxlen=max_sample_len)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['sentiment'] == -2:\n",
    "      neg2.append(row['p'])\n",
    "    elif row['sentiment'] == -1:\n",
    "      neg1.append(row['p'])\n",
    "    elif row['sentiment'] == 0:\n",
    "      zero.append(row['p'])\n",
    "    elif row['sentiment'] == 1:\n",
    "      pos1.append(row['p'])\n",
    "    elif row['sentiment'] == 2:\n",
    "      pos2.append(row['p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1303,
     "status": "ok",
     "timestamp": 1628080007838,
     "user": {
      "displayName": "Heng jing han",
      "photoUrl": "",
      "userId": "01148339297681775778"
     },
     "user_tz": -480
    },
    "id": "alpe5beOWD7O",
    "outputId": "a74f064e-f3a1-4e0c-fcfd-449738e65b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 100, 100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "deque_list = [neg2, neg1, zero, pos1, pos2]\n",
    "len_list = [len(neg2), len(neg1), len(zero), len(pos1), len(pos2)]\n",
    "print(len_list)\n",
    "merged_deque = deque()\n",
    "for i in deque_list:\n",
    "  merged_deque += i\n",
    "\n",
    "sentiment_df = pd.DataFrame(list(merged_deque), columns=[\"text\"])\n",
    "\n",
    "sentiment_list = []\n",
    "\n",
    "count = 0\n",
    "for i in range(-2, 3):\n",
    "  sentiment_list += [i] * len_list[count]\n",
    "  count += 1\n",
    "sentiment_df['sentiment'] = sentiment_list\n",
    "\n",
    "sentiment_df.to_csv(\"sentiment_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRD5c9iuxvgv"
   },
   "source": [
    "## Next is to verify the sentiment data, check if it make sense and then use it as the ground truth for training"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of 1-GetSenData.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
